---
---

@string{aps = {American Physical Society,}}

@inproceedings{DBLP:conf/sigmod/RazaCAA20,
  author    = {Aunn Raza and
               Periklis Chrysogelos and
               Angelos{-}Christos G. Anadiotis and
               Anastasia Ailamaki},
  editor    = {David Maier and
               Rachel Pottinger and
               AnHai Doan and
               Wang{-}Chiew Tan and
               Abdussalam Alawini and
               Hung Q. Ngo},
  title     = {Adaptive {HTAP} through Elastic Resource Scheduling},
  booktitle = {Proceedings of the 2020 International Conference on Management of
               Data, {SIGMOD} Conference 2020, online conference [Portland, OR, USA],
               June 14-19, 2020},
  pages     = {2043--2054},
  publisher = {{ACM}},
  year      = {2020},
  url       = {https://doi.org/10.1145/3318464.3389783},
  doi       = {10.1145/3318464.3389783},
  timestamp = {Fri, 21 Aug 2020 17:36:54 +0200},
  biburl    = {https://dblp.org/rec/conf/sigmod/RazaCAA20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  html={https://infoscience.epfl.ch/record/276997},
  pdf={adaptive-htap-technical-report.pdf},
  abbr={SIGMOD 20},
  type={CONFERENCE},
  abstract = {Modern Hybrid Transactional/Analytical Processing (HTAP) systems use an integrated data processing engine that performs analytics on fresh data, which are ingested from a transactional engine. HTAP systems typically consider data freshness at design time, and are optimized for a fixed range of freshness requirements, addressed at a performance cost for either OLTP or OLAP. The data freshness and the performance requirements of both engines, however, may vary with the workload. We approach HTAP as a scheduling problem, addressed at runtime through elastic resource management. We model an HTAP system as a set of three individual engines: an OLTP, an OLAP and a Resource and Data Exchange (RDE) engine. We devise a scheduling algorithm which traverses the HTAP design spectrum through elastic resource management, to meet the workload data freshness requirements. We propose an in-memory system design which is non-intrusive to the current state-of-art OLTP and OLAP engines, and we use it to evaluate the performance of our approach. Our evaluation shows that the performance benefit of our system for OLAP queries increases over time, reaching up to 50% compared to static schedules for 100 query sequences, while maintaining a small, and controlled, drop in the OLTP throughput.}
}

@inproceedings{DBLP:conf/cidr/RazaCSIAA20,
  author    = {Aunn Raza and
               Periklis Chrysogelos and
               Panagiotis Sioulas and
               Vladimir Indjic and
               Angelos{-}Christos G. Anadiotis and
               Anastasia Ailamaki},
  title     = {GPU-accelerated data management under the test of time},
  booktitle = {{CIDR} 2020, 10th Conference on Innovative Data Systems Research,
               Amsterdam, The Netherlands, January 12-15, 2020, Online Proceedings},
  publisher = {www.cidrdb.org},
  year      = {2020},
  url       = {http://cidrdb.org/cidr2020/papers/p18-raza-cidr20.pdf},
  timestamp = {Thu, 12 Mar 2020 11:32:37 +0100},
  biburl    = {https://dblp.org/rec/conf/cidr/RazaCSIAA20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  html={https://infoscience.epfl.ch/record/277001},
  pdf={p18-raza-cidr20.pdf},
  abbr={CIDR 20},
  type={CONFERENCE},
  abstract = {GPUs are becoming increasingly popular in large scale data center installations due to their strong, embarrassingly parallel, processing capabilities. Data management systems are riding the wave by using GPUs to accelerate query execution, mainly for analytical workloads. However, this acceleration comes at the price of a slow interconnect which imposes strong restrictions in bandwidth and latency when bringing data from the main memory to the GPU for processing. The related research in data management systems mostly relies on late materialization and data sharing to mitigate the overheads introduced by slow interconnects even in the standard CPU processing case. Finally, workload trends move beyond analytical to fresh data processing, typically referred to as Hybrid Transactional and Analytical Processing (HTAP). Therefore, we experience an evolution in three different axes: interconnect technology, GPU architecture, and workload characteristics. In this paper, we break the evolution of the technological landscape into steps and we study the applicability and performance of late materialization and data sharing in each one of them. We demonstrate that the standard PCIe interconnect substantially limits the performance of state-of-the-art GPUs and we propose a hybrid materialization approach which combines eager with lazy data transfers. Further, we show that the wide gap between GPU and PCIe throughput can be bridged through efficient data sharing techniques. Finally, we provide an H2TAP system design which removes software-level interference and we show that the interference in the memory bus is minimal, allowing data transfer optimizations as in OLAP workloads.}
}

@inproceedings{DBLP:conf/usenix/IorgulescuDRHZ17,
  author    = {Calin Iorgulescu and
               Florin Dinu and
               Aunn Raza and
               Wajih Ul Hassan and
               Willy Zwaenepoel},
  editor    = {Dilma Da Silva and
               Bryan Ford},
  title     = {Don't cry over spilled records: Memory elasticity of data-parallel
               applications and its application to cluster scheduling},
  booktitle = {2017 {USENIX} Annual Technical Conference, {USENIX} {ATC} 2017, Santa
               Clara, CA, USA, July 12-14, 2017},
  pages     = {97--109},
  publisher = {{USENIX} Association},
  year      = {2017},
  url       = {https://www.usenix.org/conference/atc17/technical-sessions/presentation/iorgulescu},
  timestamp = {Mon, 16 Jul 2018 15:47:23 +0200},
  biburl    = {https://dblp.org/rec/conf/usenix/IorgulescuDRHZ17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  html={https://www.usenix.org/conference/atc17/technical-sessions/presentation/iorgulescu},
  abbr={USENIX ATC},
  type={CONFERENCE}
}

@article{DBLP:journals/access/UsamaQRAYEHA19,
  author    = {Muhammad Usama and
               Junaid Qadir and
               Aunn Raza and
               Hunain Arif and
               Kok{-}Lim Alvin Yau and
               Yehia Elkhatib and
               Amir Hussain and
               Ala I. Al{-}Fuqaha},
  title     = {Unsupervised Machine Learning for Networking: Techniques, Applications
               and Research Challenges},
  journal   = {{IEEE} Access},
  volume    = {7},
  pages     = {65579--65615},
  year      = {2019},
  url       = {https://doi.org/10.1109/ACCESS.2019.2916648},
  doi       = {10.1109/ACCESS.2019.2916648},
  timestamp = {Fri, 27 Dec 2019 21:13:24 +0100},
  biburl    = {https://dblp.org/rec/journals/access/UsamaQRAYEHA19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  html={https://ieeexplore.ieee.org/document/8713992},
  abbr={IEEE ACCESS},
  type={JOURNAL}
}